{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'addict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# from model.PTv3 import Point\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLidarUpsample\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Lidar4US, Point\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_kitti_bin\u001b[39m(file_path):\n\u001b[1;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    Load a KITTI .bin file as a numpy array.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    :param file_path: Path to .bin file\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m    :return: Numpy array of shape (N, 4) [x, y, z, intensity]\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/js_ws/lidar_test/model/LidarUpsample.py:6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maddict\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partial\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtimm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DropPath\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'addict'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath())))\n",
    "\n",
    "# from model.PTv3 import Point\n",
    "from model.LidarUpsample import Lidar4US, Point\n",
    "\n",
    "\n",
    "def load_kitti_bin(file_path):\n",
    "    \"\"\"\n",
    "    Load a KITTI .bin file as a numpy array.\n",
    "    :param file_path: Path to .bin file\n",
    "    :return: Numpy array of shape (N, 4) [x, y, z, intensity]\n",
    "    \"\"\"\n",
    "    return np.fromfile(file_path, dtype=np.float32).reshape(-1, 4)\n",
    "\n",
    "\n",
    "def kitti_to_dict(file_path, grid_size=0.05, batch_id=0):\n",
    "    \"\"\"\n",
    "    Convert a KITTI .bin file to a Point object suitable for the model.\n",
    "    :param file_path: Path to .bin file\n",
    "    :param grid_size: Grid size for quantization\n",
    "    :param batch_id: Batch ID for the point cloud\n",
    "    :return: Point object\n",
    "    \"\"\"\n",
    "    raw_data = load_kitti_bin(file_path)\n",
    "    coords = raw_data[:, :3]  # x, y, z\n",
    "    intensity = raw_data[:, 3:4]  # intensity as a feature\n",
    "\n",
    "    # Combine coords and intensity as features\n",
    "    features = torch.cat([\n",
    "        torch.tensor(coords, dtype=torch.float32),\n",
    "        torch.tensor(intensity, dtype=torch.float32)\n",
    "    ], dim=1)\n",
    "\n",
    "    batch_tensor = torch.full((features.shape[0],), batch_id, dtype=torch.int64)\n",
    "\n",
    "    # Create Point object\n",
    "    data_dict = {\n",
    "        \"coord\": features[:, :3].to(\"cuda\"),  # Coordinates (x, y, z)\n",
    "        \"feat\": features[:,:3].to(\"cuda\"),\n",
    "        \"batch\": batch_tensor.to(\"cuda\"),  # Batch IDs\n",
    "        \"grid_size\" : torch.tensor(0.01).to(\"cuda\")\n",
    "    }\n",
    "    return data_dict\n",
    "\n",
    "def kitti_to_dict(file_path, grid_size=0.05, batch_id=0):\n",
    "    raw_data = load_kitti_bin(file_path)\n",
    "    coords = raw_data[:, :3]  # x, y, z\n",
    "    intensity = raw_data[:, 3:4]  # intensity as a feature\n",
    "\n",
    "    # Combine coords and intensity as features\n",
    "    features = torch.cat([\n",
    "        torch.tensor(coords, dtype=torch.float32),\n",
    "        torch.tensor(intensity, dtype=torch.float32)\n",
    "    ], dim=1)\n",
    "\n",
    "    batch_tensor = torch.full((features.shape[0],), batch_id, dtype=torch.int64)\n",
    "\n",
    "    # Create Point object\n",
    "    data_dict = {\n",
    "        \"coord\": features[:, :3].to(\"cuda\"),  # Coordinates (x, y, z)\n",
    "        \"feat\": features[:,:3].to(\"cuda\"),  # Coordinates (x, y, z)\n",
    "        \"batch\": batch_tensor.to(\"cuda\"),  # Batch IDs\n",
    "        \"grid_size\" : torch.tensor(0.01).to(\"cuda\")\n",
    "    }\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "class PointCloudDataset(Dataset):\n",
    "    def __init__(self, file_paths, grid_size=0.05):\n",
    "        self.file_paths = file_paths\n",
    "        self.grid_size = grid_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_paths[idx]\n",
    "        batch_id = idx\n",
    "        return kitti_to_dict(file_path, grid_size=self.grid_size, batch_id=batch_id)\n",
    "\n",
    "\n",
    "class MAELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, pred_points, gt_points):\n",
    "        \"\"\"\n",
    "        Compute Mean Absolute Error (MAE) Loss.\n",
    "        :param pred_points: Predicted upsampled points [B, N, 3]\n",
    "        :param gt_points: Ground truth points [B, M, 3]\n",
    "        :return: MAE Loss\n",
    "        \"\"\"\n",
    "        # Compute absolute difference between predicted and ground truth\n",
    "        loss = torch.abs(pred_points - gt_points)\n",
    "        # Return the mean over all the points\n",
    "        return torch.mean(loss)\n",
    "\n",
    "\n",
    "## !!gt and train has the same filename!!\n",
    "train_file_paths = glob(\"/home/server01/js_ws/dataset/sparse_pointclouds_kitti/train/*.bin\", recursive=True)\n",
    "gt_file_paths = glob(\"/home/server01/js_ws/dataset/sparse_pointclouds_kitti/GT/*.bin\")\n",
    "\n",
    "train_dataset = PointCloudDataset(train_file_paths)\n",
    "gt_dataset = PointCloudDataset(gt_file_paths)\n",
    "\n",
    "model = Lidar4US(\n",
    "    in_channels=3,\n",
    "    drop_path=0.3,\n",
    "    block_depth=(2, 2, 2, 6, 6, 2),\n",
    "    enc_channels=(32, 64, 128, 256, 512, 1024),\n",
    "    enc_n_heads=(2, 4, 8, 16, 32, 64),\n",
    "    enc_patch_size=(1024, 1024, 1024, 1024, 1024, 1024),\n",
    "    qkv_bias=True,\n",
    "    qk_scale=None,\n",
    "    attn_drop=0.0,\n",
    "    proj_drop=0.0,\n",
    "    mlp_ratio=4,\n",
    "    stride=(2, 2, 2, 4, 4),\n",
    "    dec_depths=(2, 2, 4, 2, 2),\n",
    "    dec_n_head=(4, 4, 8, 16, 32),\n",
    "    dec_patch_size=(1024, 1024, 1024, 1024, 1024, ),\n",
    "    dec_channels=(32, 64, 128, 256, 512),\n",
    "    out_channel = 3,\n",
    "    order=(\"z\", \"z-trans\", \"hilbert\", \"hilbert-trans\")\n",
    ")\n",
    "\n",
    "loss_fn = MAELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model.to(device)\n",
    "loss_fn.to(device)\n",
    "\n",
    "## TEST 1 just make x30 size output(11/22)\n",
    "\n",
    "serialized_gt = []\n",
    "orders=(\"z\", \"z-trans\", \"hilbert\", \"hilbert-trans\")\n",
    "\n",
    "for gt in gt_dataset:\n",
    "    p_gt = Point(gt)\n",
    "    tmp = []\n",
    "    tmp.append(p_gt.serialization(orders,shuffle_orders=False))\n",
    "    serialized_gt.append(tuple(tmp))\n",
    "    print(serialized_gt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam2",
   "language": "python",
   "name": "sam2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
